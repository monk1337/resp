{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14f0a707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "# RESP Package - API Examples\n",
    "# This notebook demonstrates both Simple and Advanced API usage\n",
    "\n",
    "# Advanced API - Direct class imports (Original style)\n",
    "from resp.apis.serp_api import Serp\n",
    "from resp.apis.cnnp import connected_papers\n",
    "from resp.apis.semantic_s import Semantic_Scholar\n",
    "from resp.apis.acm_api import ACM\n",
    "from resp.apis.arxiv_api import Arxiv\n",
    "from resp.resp import Resp\n",
    "\n",
    "# Simple API - Module-level imports (Recommended for new code)\n",
    "from resp import arxiv, semantic_scholar, acm, google_scholar\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96b27bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è  No SerpAPI key - Using free sources only (Arxiv, Semantic Scholar)\n",
      "   Get free key at https://serpapi.com/\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "import os\n",
    "\n",
    "# Paper to analyze\n",
    "Paper_names = ['Zero-shot learning with common sense knowledge graphs']\n",
    "keyword = ['Zero-shot learning']\n",
    "\n",
    "# Google Scholar features require SerpAPI key\n",
    "# Get free key at https://serpapi.com/\n",
    "# Set via environment: export SERPAPI_KEY=\"your_key\"\n",
    "api_key = os.environ.get('SERPAPI_KEY', \"\")\n",
    "\n",
    "if api_key:\n",
    "    print(\"‚úÖ SerpAPI key found - Google Scholar features enabled\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  No SerpAPI key - Using free sources only (Arxiv, Semantic Scholar)\")\n",
    "    print(\"   Get free key at https://serpapi.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f677a735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Serp client initialized (Advanced API)\n",
      "‚úÖ Google Scholar initialized (Simple API)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Google Scholar client (if API key available)\n",
    "if api_key:\n",
    "    # Method 1: Advanced API\n",
    "    qs = Serp(api_key)\n",
    "    print(\"‚úÖ Serp client initialized (Advanced API)\")\n",
    "    \n",
    "    # Method 2: Simple API\n",
    "    google_scholar.set_api_key(api_key)\n",
    "    print(\"‚úÖ Google Scholar initialized (Simple API)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping Google Scholar setup - no API key\")\n",
    "    print(\"   Free sources (Arxiv, Semantic Scholar, ACM) work without API key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26406bc",
   "metadata": {},
   "source": [
    "## Example 1: Arxiv Search (No API Key Required)\n",
    "\n",
    "Demonstrates both Simple and Advanced API usage for Arxiv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcda374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:11<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simple API: Found 100 papers\n",
      "                                               title  \\\n",
      "0  Maintaining SUV Accuracy in Low-Count PET with...   \n",
      "1  AttMetNet: Attention-Enhanced Deep Neural Netw...   \n",
      "2  Neural Networks for Predicting Permeability Te...   \n",
      "3  Drainage: A Unifying Framework for Addressing ...   \n",
      "4  Structured Uncertainty Similarity Score (SUSS)...   \n",
      "\n",
      "                               link  \n",
      "0  https://arxiv.org/abs/2512.02917  \n",
      "1  https://arxiv.org/abs/2512.02751  \n",
      "2  https://arxiv.org/abs/2512.01517  \n",
      "3  https://arxiv.org/abs/2512.03182  \n",
      "4  https://arxiv.org/abs/2512.03701  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Advanced API: Found 50 papers\n",
      "                                               title  \\\n",
      "0              Learning Visual Affordance from Audio   \n",
      "1  Chain of Unit-Physics: A Primitive-Centric App...   \n",
      "2  Few-shot Protein Fitness Prediction via In-con...   \n",
      "3  A Comparative Study on How Data Normalization ...   \n",
      "4  Behavioral Indicators of Loneliness: Predictin...   \n",
      "\n",
      "                               link  \n",
      "0  https://arxiv.org/abs/2512.02005  \n",
      "1  https://arxiv.org/abs/2512.01010  \n",
      "2  https://arxiv.org/abs/2512.02315  \n",
      "3  https://arxiv.org/abs/2512.02833  \n",
      "4  https://arxiv.org/abs/2512.00326  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Simple API (Recommended)\n",
    "papers = arxiv.search_papers(\"deep learning\", max_results=2)\n",
    "print(f\"‚úÖ Simple API: Found {len(papers)} papers\")\n",
    "print(papers[['title', 'link']].head())\n",
    "\n",
    "# Advanced API (Original style)\n",
    "ap = Arxiv()\n",
    "papers_adv = ap.arxiv('Zero-shot learning', max_pages=1)\n",
    "print(f\"\\n‚úÖ Advanced API: Found {len(papers_adv)} papers\")\n",
    "print(papers_adv[['title', 'link']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9274256e",
   "metadata": {},
   "source": [
    "## Example 2: Google Scholar - Get Citations (Requires API Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "075f9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page : 1\n",
      "Page : 2\n",
      "Page : 3\n",
      "Page : 4\n",
      "Page : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved citations for 'Zero-shot learning with common sense knowledge graphs'\n",
      "   Found 1 citation collections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all citations of a paper\n",
    "if api_key:\n",
    "    # Using Advanced API\n",
    "    result = qs.get_citations(Paper_names[0])\n",
    "    print(f\"‚úÖ Retrieved citations for '{Paper_names[0]}'\")\n",
    "    print(f\"   Found {len(result)} citation collections\")\n",
    "    \n",
    "    # Alternative: Using Simple API\n",
    "    # citations = google_scholar.get_citations(Paper_names[0])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipped - Requires SerpAPI key\")\n",
    "    print(\"   Get free key at: https://serpapi.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d6c5c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample citations (key: e85a09d25b834f703c5ec455a51e5615):\n",
      "                                               title  \\\n",
      "0  Knowledge graphs meet multi-modal learning: A ...   \n",
      "1  Zero-shot and few-shot learning with knowledge...   \n",
      "2  Debiased learning from naturally imbalanced ps...   \n",
      "3  Does clip bind concepts? probing compositional...   \n",
      "4  Zero-shot node classification with graph contr...   \n",
      "\n",
      "                                                link  \\\n",
      "0                   https://arxiv.org/abs/2402.05391   \n",
      "1  https://ieeexplore.ieee.org/abstract/document/...   \n",
      "2  http://openaccess.thecvf.com/content/CVPR2022/...   \n",
      "3   https://aclanthology.org/2024.findings-eacl.101/   \n",
      "4         https://openreview.net/forum?id=8wGXnjRLSy   \n",
      "\n",
      "                                             snippet  \n",
      "0  Knowledge Graphs (KGs) play a pivotal role in ...  \n",
      "1  Machine learning (ML), especially deep neural ...  \n",
      "2  This work studies the bias issue of pseudo-lab...  \n",
      "3  Large-scale neural network models combining te...  \n",
      "4  This paper studies zero-shot node classificati...  \n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the citations\n",
    "if api_key and 'result' in locals():\n",
    "    # Show first result\n",
    "    first_key = list(result.keys())[0]\n",
    "    print(f\"Sample citations (key: {first_key}):\")\n",
    "    print(result[first_key].head())\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results to display - SerpAPI key required\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c008b818",
   "metadata": {},
   "source": [
    "### Get all related paper of a single paper from google scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a4fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 3: Google Scholar - Get Related Papers (Requires API Key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "095c6a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                             | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page : 1\n",
      "Page : 2\n",
      "Page : 3\n",
      "Page : 4\n",
      "Page : 5\n",
      "Page : 6\n",
      "Page : 7\n",
      "Page : 8\n",
      "Page : 9\n",
      "Page : 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:13<00:00, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved related papers for 'Zero-shot learning with common sense knowledge graphs'\n",
      "   Found 1 collections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all related papers from Google Scholar\n",
    "if api_key:\n",
    "    # Using Advanced API\n",
    "    rl_result = qs.get_related_pages(Paper_names[0])\n",
    "    print(f\"‚úÖ Retrieved related papers for '{Paper_names[0]}'\")\n",
    "    print(f\"   Found {len(rl_result)} collections\")\n",
    "    \n",
    "    # Alternative: Using Simple API\n",
    "    # related = google_scholar.get_related_papers(Paper_names[0])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipped - Requires SerpAPI key\")\n",
    "    print(\"   Get free key at: https://serpapi.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbcbe01",
   "metadata": {},
   "source": [
    "# Display related papers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9add89c-ed0f-436a-b06a-5c639c9de734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample related papers (key: 5d0128d1ea70972349587d570158f12c):\n",
      "                                                title  \\\n",
      "0   Zero-shot learning with common sense knowledge...   \n",
      "1   Zero-shot learning via contrastive learning on...   \n",
      "2   Semantic guided knowledge graph for large-scal...   \n",
      "3   Explainable zero-shot learning via attentive g...   \n",
      "4       Ontozsl: Ontology-enhanced zero-shot learning   \n",
      "..                                                ...   \n",
      "95  Adaptive relation-aware network for zero-shot ...   \n",
      "96  VMAN: A virtual mainstay alignment network for...   \n",
      "97  Estimation of near-instance-level attribute bo...   \n",
      "98  Episode-based prototype generating network for...   \n",
      "99  RE-GZSL: relation extrapolation for generalize...   \n",
      "\n",
      "                                                 link  \\\n",
      "0                    https://arxiv.org/abs/2006.10713   \n",
      "1   https://openaccess.thecvf.com/content/ICCV2021...   \n",
      "2   https://www.sciencedirect.com/science/article/...   \n",
      "3   https://journals.sagepub.com/doi/abs/10.3233/S...   \n",
      "4   https://dl.acm.org/doi/abs/10.1145/3442381.345...   \n",
      "..                                                ...   \n",
      "95  https://www.sciencedirect.com/science/article/...   \n",
      "96  https://ieeexplore.ieee.org/abstract/document/...   \n",
      "97  https://link.springer.com/article/10.1007/s112...   \n",
      "98  http://openaccess.thecvf.com/content_CVPR_2020...   \n",
      "99  https://ieeexplore.ieee.org/abstract/document/...   \n",
      "\n",
      "                                              snippet  \n",
      "0   Zero-shot learning relies on semantic class re...  \n",
      "1   Abstract Graph Convolutional Networks (GCNs), ...  \n",
      "2   Zero-shot learning has received growing attent...  \n",
      "3   Zero-shot learning (ZSL) which aims to deal wi...  \n",
      "4   Zero-shot Learning (ZSL), which aims to predic...  \n",
      "..                                                ...  \n",
      "95  Supervised learning-based image classification...  \n",
      "96  Transductive zero-shot learning (TZSL) extends...  \n",
      "97  Abstract Zero-Shot Learning (ZSL) involves tra...  \n",
      "98  We introduce a simple yet effective episode-ba...  \n",
      "99  Unlike Conventional Zero-Shot Learning (CZSL) ...  \n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "if api_key and 'rl_result' in locals():\n",
    "    first_key = list(rl_result.keys())[0]\n",
    "    print(f\"Sample related papers (key: {first_key}):\")\n",
    "    print(rl_result[first_key])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No results to display - SerpAPI key required\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b6008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 4: Connected Papers (Requires Selenium)\n",
    "# Install with: `pip install respsearch[selenium]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a60a80e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Error: WebDriver.__init__() got an unexpected keyword argument 'des...\n"
     ]
    }
   ],
   "source": [
    "# Get connected papers (requires selenium)\n",
    "try:\n",
    "    cp = connected_papers()\n",
    "    papers = cp.download_papers(Paper_names[0], n=1)\n",
    "    print(f\"‚úÖ Downloaded {len(papers)} connected papers\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  Connected Papers requires Selenium\")\n",
    "    print(\"   Install with: pip install respsearch[selenium]\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error: {str(e)[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ab3e7",
   "metadata": {},
   "source": [
    "### Get relevant papers from arxiv based on keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5b5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 5: Arxiv Search (Both APIs Demonstrated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c20605",
   "metadata": {},
   "source": [
    "### Get relevant papers from ACM digital library based on keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d74c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 6: ACM Digital Library Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb29044",
   "metadata": {},
   "outputs": [],
   "source": [
    "acm_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ca08c",
   "metadata": {},
   "source": [
    "### Get relevant papers from Semantic_Scholar based on keyword\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3608a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 7: Semantic Scholar Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e714eb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Simple API: Found 10 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Advanced API: Found 10 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Semantic Scholar search (may rate-limit)\n",
    "try:\n",
    "    import time\n",
    "    time.sleep(2)  # Brief pause to avoid rate limits\n",
    "    \n",
    "    # Simple API\n",
    "    ss_papers = semantic_scholar.search_papers('Zero-shot learning', max_results=1)\n",
    "    print(f\"‚úÖ Simple API: Found {len(ss_papers)} papers\")\n",
    "    \n",
    "    # Advanced API\n",
    "    sc = Semantic_Scholar()\n",
    "    sc_result = sc.ss('Zero-shot learning', max_pages=1)\n",
    "    print(f\"‚úÖ Advanced API: Found {len(sc_result)} papers\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Semantic Scholar may be rate-limiting\")\n",
    "    print(f\"   Error: {str(e)[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5880338",
   "metadata": {},
   "source": [
    "### Get relevant papers from ACL based on keyword ( based on serp_api )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 8: ACL Anthology (Requires SerpAPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f6b6cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resp engine initialized\n"
     ]
    }
   ],
   "source": [
    "# ACL Anthology search via Resp class\n",
    "if api_key:\n",
    "    paper_engine = Resp(api_key)\n",
    "    print(\"‚úÖ Resp engine initialized\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Resp class requires SerpAPI key\")\n",
    "    print(\"   Get free key at: https://serpapi.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78d68907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page : 1\n",
      "Page : 2\n",
      "‚úÖ Found 20 papers from ACL Anthology\n"
     ]
    }
   ],
   "source": [
    "# Search ACL Anthology\n",
    "if api_key:\n",
    "    acl_result = paper_engine.acl('Zero-shot learning', max_pages=2)\n",
    "    print(f\"‚úÖ Found {len(acl_result)} papers from ACL Anthology\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipped - Requires SerpAPI key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bba62c",
   "metadata": {},
   "source": [
    "### Get relevant papers from PMLR based on keyword ( based on serp_api )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c43501eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page : 1\n",
      "Page : 2\n"
     ]
    }
   ],
   "source": [
    "### Get relevant papers from PMLR based on keyword ( based on serp_api )\n",
    "pmlr_result = paper_engine.pmlr('Zero-shot learning', max_pages = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d479b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An embarrassingly simple approach to zero-shot...</td>\n",
       "      <td>https://proceedings.mlr.press/v37/romera-pared...</td>\n",
       "      <td>Zero-shot learning consists in learning how to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evolving Semantic Prototype Improves Generativ...</td>\n",
       "      <td>https://proceedings.mlr.press/v202/chen23l.html</td>\n",
       "      <td>In zero-shot learning (ZSL), generative method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A simple and effective model for generalized z...</td>\n",
       "      <td>https://proceedings.mlr.press/v161/daghaghi21a...</td>\n",
       "      <td>Zero-Shot Learning (ZSL) is a classification t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Context-Aware Zero-Shot Learning for Object Re...</td>\n",
       "      <td>https://proceedings.mlr.press/v97/zablocki19a....</td>\n",
       "      <td>Zero-Shot Learning (ZSL) aims at classifying u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Frozen Language Model Helps ECG Zero-Shot Lear...</td>\n",
       "      <td>https://proceedings.mlr.press/v227/li24a/li24a...</td>\n",
       "      <td>Zero-shot classification is performed after pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Language Models as Zero-Shot Planners: Extract...</td>\n",
       "      <td>https://proceedings.mlr.press/v162/huang22a.html</td>\n",
       "      <td>In this paper, we investigate the possibility ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zero-Shot Task Generalization with Robotic Imi...</td>\n",
       "      <td>https://proceedings.mlr.press/v164/jang22a/jan...</td>\n",
       "      <td>In this paper, we study the problem of enablin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zero-Shot Text-to-Image Generation</td>\n",
       "      <td>https://proceedings.mlr.press/v139/ramesh21a/r...</td>\n",
       "      <td>Text-to-image generation has traditionally fo-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multi-Label Generalized Zero Shot Learning for...</td>\n",
       "      <td>https://proceedings.mlr.press/v149/hayat21a/ha...</td>\n",
       "      <td>However, radiologists can recognize previously...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Unsupervised Zero-Shot Reinforcement Learning ...</td>\n",
       "      <td>https://proceedings.mlr.press/v235/frans24a.html</td>\n",
       "      <td>In this work, we present a functional reward e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zero-shot AutoML with Pretrained Models</td>\n",
       "      <td>https://proceedings.mlr.press/v162/ozturk22a.html</td>\n",
       "      <td>Our domain-independent meta-learning approach ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SDM-Net: A Simple and Effective Model for Gene...</td>\n",
       "      <td>https://proceedings.mlr.press/v161/daghaghi21a...</td>\n",
       "      <td>Zero-Shot Learning (ZSL) is a classification t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zero-Shot Task Generalization with Multi-Task ...</td>\n",
       "      <td>http://proceedings.mlr.press/v70/oh17a.html</td>\n",
       "      <td>For generalization over unseen instructions, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Evolving Semantic Prototype Improves Generativ...</td>\n",
       "      <td>https://proceedings.mlr.press/v202/chen23l/che...</td>\n",
       "      <td>In zero-shot learning (ZSL), generative method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zero-Shot Reward Specification via Grounded Na...</td>\n",
       "      <td>https://proceedings.mlr.press/v162/mahmoudieh2...</td>\n",
       "      <td>Reward signals in reinforcement learning are e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Co-Representation Network for Generalized Zero...</td>\n",
       "      <td>http://proceedings.mlr.press/v97/zhang19l/zhan...</td>\n",
       "      <td>Generalized zero-shot learning is a significan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zero-Shot Open-Vocabulary OOD Object Detection...</td>\n",
       "      <td>https://proceedings.mlr.press/v265/sinhamahapa...</td>\n",
       "      <td>We propose an automated framework zPROD, for z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Learning to Route Among Specialized Experts fo...</td>\n",
       "      <td>https://proceedings.mlr.press/v235/muqeeth24a....</td>\n",
       "      <td>In this work, we propose Post-Hoc Adaptive Tok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Zero-shot Sim-to-Real Transfer for Reinforceme...</td>\n",
       "      <td>https://proceedings.mlr.press/v283/yang25b.html</td>\n",
       "      <td>This work introduces a reinforcement learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Zero-Shot Reinforcement Learning via Function ...</td>\n",
       "      <td>https://proceedings.mlr.press/v235/ingebrand24...</td>\n",
       "      <td>To achieve zero-shot transfer, we introduce th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   An embarrassingly simple approach to zero-shot...   \n",
       "1   Evolving Semantic Prototype Improves Generativ...   \n",
       "2   A simple and effective model for generalized z...   \n",
       "3   Context-Aware Zero-Shot Learning for Object Re...   \n",
       "4   Frozen Language Model Helps ECG Zero-Shot Lear...   \n",
       "5   Language Models as Zero-Shot Planners: Extract...   \n",
       "6   Zero-Shot Task Generalization with Robotic Imi...   \n",
       "7                  Zero-Shot Text-to-Image Generation   \n",
       "8   Multi-Label Generalized Zero Shot Learning for...   \n",
       "9   Unsupervised Zero-Shot Reinforcement Learning ...   \n",
       "10            Zero-shot AutoML with Pretrained Models   \n",
       "11  SDM-Net: A Simple and Effective Model for Gene...   \n",
       "12  Zero-Shot Task Generalization with Multi-Task ...   \n",
       "13  Evolving Semantic Prototype Improves Generativ...   \n",
       "14  Zero-Shot Reward Specification via Grounded Na...   \n",
       "15  Co-Representation Network for Generalized Zero...   \n",
       "16  Zero-Shot Open-Vocabulary OOD Object Detection...   \n",
       "17  Learning to Route Among Specialized Experts fo...   \n",
       "18  Zero-shot Sim-to-Real Transfer for Reinforceme...   \n",
       "19  Zero-Shot Reinforcement Learning via Function ...   \n",
       "\n",
       "                                                 link  \\\n",
       "0   https://proceedings.mlr.press/v37/romera-pared...   \n",
       "1     https://proceedings.mlr.press/v202/chen23l.html   \n",
       "2   https://proceedings.mlr.press/v161/daghaghi21a...   \n",
       "3   https://proceedings.mlr.press/v97/zablocki19a....   \n",
       "4   https://proceedings.mlr.press/v227/li24a/li24a...   \n",
       "5    https://proceedings.mlr.press/v162/huang22a.html   \n",
       "6   https://proceedings.mlr.press/v164/jang22a/jan...   \n",
       "7   https://proceedings.mlr.press/v139/ramesh21a/r...   \n",
       "8   https://proceedings.mlr.press/v149/hayat21a/ha...   \n",
       "9    https://proceedings.mlr.press/v235/frans24a.html   \n",
       "10  https://proceedings.mlr.press/v162/ozturk22a.html   \n",
       "11  https://proceedings.mlr.press/v161/daghaghi21a...   \n",
       "12        http://proceedings.mlr.press/v70/oh17a.html   \n",
       "13  https://proceedings.mlr.press/v202/chen23l/che...   \n",
       "14  https://proceedings.mlr.press/v162/mahmoudieh2...   \n",
       "15  http://proceedings.mlr.press/v97/zhang19l/zhan...   \n",
       "16  https://proceedings.mlr.press/v265/sinhamahapa...   \n",
       "17  https://proceedings.mlr.press/v235/muqeeth24a....   \n",
       "18    https://proceedings.mlr.press/v283/yang25b.html   \n",
       "19  https://proceedings.mlr.press/v235/ingebrand24...   \n",
       "\n",
       "                                              snippet  \n",
       "0   Zero-shot learning consists in learning how to...  \n",
       "1   In zero-shot learning (ZSL), generative method...  \n",
       "2   Zero-Shot Learning (ZSL) is a classification t...  \n",
       "3   Zero-Shot Learning (ZSL) aims at classifying u...  \n",
       "4   Zero-shot classification is performed after pr...  \n",
       "5   In this paper, we investigate the possibility ...  \n",
       "6   In this paper, we study the problem of enablin...  \n",
       "7   Text-to-image generation has traditionally fo-...  \n",
       "8   However, radiologists can recognize previously...  \n",
       "9   In this work, we present a functional reward e...  \n",
       "10  Our domain-independent meta-learning approach ...  \n",
       "11  Zero-Shot Learning (ZSL) is a classification t...  \n",
       "12  For generalization over unseen instructions, w...  \n",
       "13  In zero-shot learning (ZSL), generative method...  \n",
       "14  Reward signals in reinforcement learning are e...  \n",
       "15  Generalized zero-shot learning is a significan...  \n",
       "16  We propose an automated framework zPROD, for z...  \n",
       "17  In this work, we propose Post-Hoc Adaptive Tok...  \n",
       "18  This work introduces a reinforcement learning ...  \n",
       "19  To achieve zero-shot transfer, we introduce th...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmlr_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3a810",
   "metadata": {},
   "source": [
    "### Get relevant papers from NeurlPS based on keyword ( based on serp_api )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33f8ea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page : 1\n",
      "Page : 2\n"
     ]
    }
   ],
   "source": [
    "### Get relevant papers from nips based on keyword ( based on serp_api )\n",
    "nips_result = paper_engine.nips('Zero-shot learning', max_pages = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "debd24cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zero-Shot Learning Through Cross-Modal Transfer</td>\n",
       "      <td>https://papers.nips.cc/paper/5027-zero-shot-le...</td>\n",
       "      <td>This work introduces a model that can recogniz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zero-shot Learning with Semantic Output Codes</td>\n",
       "      <td>https://papers.nips.cc/paper/3650-zero-shot-le...</td>\n",
       "      <td>We consider the problem of zero-shot learning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Large Language Models are Zero-Shot Reasoners</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2022/...</td>\n",
       "      <td>Pretrained large language models (LLMs) are wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Semantic-Guided Multi-Attention Localization f...</td>\n",
       "      <td>http://papers.nips.cc/paper/9632-semantic-guid...</td>\n",
       "      <td>Zero-shot learning extends the conventional ob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zero-shot Learning via Simultaneous Generating...</td>\n",
       "      <td>https://papers.nips.cc/paper/8300-zero-shot-le...</td>\n",
       "      <td>To overcome the absence of training data for u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Generating Training Data with Language Models</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2022/...</td>\n",
       "      <td>In this paper, we present a simple approach th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Generalized Zero-Shot Learning with Deep Calib...</td>\n",
       "      <td>http://papers.nips.cc/paper/7471-generalized-z...</td>\n",
       "      <td>Zero-shot learning leverages semantic represen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zero-shot causal learning</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2023/...</td>\n",
       "      <td>Here, we consider zero-shot causal learning: p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zero-shot causal learning - Stanford Computer ...</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2023/...</td>\n",
       "      <td>Our approach allows us to predict the causal e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Domain-Invariant Projection Learning for Zero-...</td>\n",
       "      <td>https://papers.nips.cc/paper/7380-domain-invar...</td>\n",
       "      <td>Zero-shot learning (ZSL) aims to recognize uns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zero-shot causal learning - Stanford Computer ...</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2023/...</td>\n",
       "      <td>Our approach allows us to predict the causal e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zero-shot recognition with unreliable attributes</td>\n",
       "      <td>https://papers.nips.cc/paper/5290-zero-shot-re...</td>\n",
       "      <td>Abstract. In principle, zero-shot learning mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dual Adversarial Semantics-Consistent Network ...</td>\n",
       "      <td>https://papers.nips.cc/paper/8846-dual-adversa...</td>\n",
       "      <td>Generalized zero-shot learning (GZSL) is a cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Topology-Preserving Reservoirs for Generalized...</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2024/...</td>\n",
       "      <td>In this paper, we focus on a more challenging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zero-Shot Semantic Segmentation</td>\n",
       "      <td>https://papers.nips.cc/paper/8338-zero-shot-se...</td>\n",
       "      <td>In this paper, we introduce the new task of ze...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zero-Shot Reinforcement Learning from Low Qual...</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2024/...</td>\n",
       "      <td>Zero-shot reinforcement learning (RL) promises...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fine-Grained Zero-Shot Learning with DNA as Si...</td>\n",
       "      <td>https://papers.nips.cc/paper/2021/file/a18630a...</td>\n",
       "      <td>Fine-grained zero-shot learning task requires ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Uncertainty-Aware Learning for Zero-Shot Seman...</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2020/...</td>\n",
       "      <td>Zero-shot semantic segmentation (ZSS) aims to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dual Progressive Prototype Network for General...</td>\n",
       "      <td>https://papers.nips.cc/paper/2021/hash/1700002...</td>\n",
       "      <td>Generalized Zero-Shot Learning (GZSL) aims to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FAST: A Dual-tier Few-Shot Learning Paradigm f...</td>\n",
       "      <td>https://papers.nips.cc/paper_files/paper/2024/...</td>\n",
       "      <td>First, we compared FAST with zero-shot learnin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0     Zero-Shot Learning Through Cross-Modal Transfer   \n",
       "1       Zero-shot Learning with Semantic Output Codes   \n",
       "2       Large Language Models are Zero-Shot Reasoners   \n",
       "3   Semantic-Guided Multi-Attention Localization f...   \n",
       "4   Zero-shot Learning via Simultaneous Generating...   \n",
       "5       Generating Training Data with Language Models   \n",
       "6   Generalized Zero-Shot Learning with Deep Calib...   \n",
       "7                           Zero-shot causal learning   \n",
       "8   Zero-shot causal learning - Stanford Computer ...   \n",
       "9   Domain-Invariant Projection Learning for Zero-...   \n",
       "10  Zero-shot causal learning - Stanford Computer ...   \n",
       "11   Zero-shot recognition with unreliable attributes   \n",
       "12  Dual Adversarial Semantics-Consistent Network ...   \n",
       "13  Topology-Preserving Reservoirs for Generalized...   \n",
       "14                    Zero-Shot Semantic Segmentation   \n",
       "15  Zero-Shot Reinforcement Learning from Low Qual...   \n",
       "16  Fine-Grained Zero-Shot Learning with DNA as Si...   \n",
       "17  Uncertainty-Aware Learning for Zero-Shot Seman...   \n",
       "18  Dual Progressive Prototype Network for General...   \n",
       "19  FAST: A Dual-tier Few-Shot Learning Paradigm f...   \n",
       "\n",
       "                                                 link  \\\n",
       "0   https://papers.nips.cc/paper/5027-zero-shot-le...   \n",
       "1   https://papers.nips.cc/paper/3650-zero-shot-le...   \n",
       "2   https://papers.nips.cc/paper_files/paper/2022/...   \n",
       "3   http://papers.nips.cc/paper/9632-semantic-guid...   \n",
       "4   https://papers.nips.cc/paper/8300-zero-shot-le...   \n",
       "5   https://papers.nips.cc/paper_files/paper/2022/...   \n",
       "6   http://papers.nips.cc/paper/7471-generalized-z...   \n",
       "7   https://papers.nips.cc/paper_files/paper/2023/...   \n",
       "8   https://papers.nips.cc/paper_files/paper/2023/...   \n",
       "9   https://papers.nips.cc/paper/7380-domain-invar...   \n",
       "10  https://papers.nips.cc/paper_files/paper/2023/...   \n",
       "11  https://papers.nips.cc/paper/5290-zero-shot-re...   \n",
       "12  https://papers.nips.cc/paper/8846-dual-adversa...   \n",
       "13  https://papers.nips.cc/paper_files/paper/2024/...   \n",
       "14  https://papers.nips.cc/paper/8338-zero-shot-se...   \n",
       "15  https://papers.nips.cc/paper_files/paper/2024/...   \n",
       "16  https://papers.nips.cc/paper/2021/file/a18630a...   \n",
       "17  https://papers.nips.cc/paper_files/paper/2020/...   \n",
       "18  https://papers.nips.cc/paper/2021/hash/1700002...   \n",
       "19  https://papers.nips.cc/paper_files/paper/2024/...   \n",
       "\n",
       "                                              snippet  \n",
       "0   This work introduces a model that can recogniz...  \n",
       "1   We consider the problem of zero-shot learning,...  \n",
       "2   Pretrained large language models (LLMs) are wi...  \n",
       "3   Zero-shot learning extends the conventional ob...  \n",
       "4   To overcome the absence of training data for u...  \n",
       "5   In this paper, we present a simple approach th...  \n",
       "6   Zero-shot learning leverages semantic represen...  \n",
       "7   Here, we consider zero-shot causal learning: p...  \n",
       "8   Our approach allows us to predict the causal e...  \n",
       "9   Zero-shot learning (ZSL) aims to recognize uns...  \n",
       "10  Our approach allows us to predict the causal e...  \n",
       "11  Abstract. In principle, zero-shot learning mak...  \n",
       "12  Generalized zero-shot learning (GZSL) is a cha...  \n",
       "13  In this paper, we focus on a more challenging ...  \n",
       "14  In this paper, we introduce the new task of ze...  \n",
       "15  Zero-shot reinforcement learning (RL) promises...  \n",
       "16  Fine-grained zero-shot learning task requires ...  \n",
       "17  Zero-shot semantic segmentation (ZSS) aims to ...  \n",
       "18  Generalized Zero-Shot Learning (GZSL) aims to ...  \n",
       "19  First, we compared FAST with zero-shot learnin...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nips_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c173a",
   "metadata": {},
   "source": [
    "#### Get relevant papers from any conference website based on keyword ( based on serp_api )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c13aac",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the RESP package with both API styles:\n",
    "\n",
    "### ‚úÖ Free Sources (No API Key Required)\n",
    "- **Arxiv** - `arxiv.search_papers()`\n",
    "- **Semantic Scholar** - `semantic_scholar.search_papers()`  \n",
    "- **ACM** - `acm.search_papers()` (may have limited results)\n",
    "\n",
    "### üîë Requires SerpAPI Key\n",
    "- **Google Scholar** - Citations, related papers\n",
    "- **Resp Class** - ACL, PMLR, NeurIPS, etc.\n",
    "\n",
    "### üì¶ Requires Selenium\n",
    "- **Connected Papers** - Install with `pip install respsearch[selenium]`\n",
    "\n",
    "### üìù API Styles\n",
    "1. **Simple API** (Recommended): `from resp import arxiv, semantic_scholar`\n",
    "2. **Advanced API** (Original): Direct class imports for more control\n",
    "\n",
    "Get SerpAPI key: https://serpapi.com/ (100 free searches/month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "739e2f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page : 1\n"
     ]
    }
   ],
   "source": [
    "websit_result = paper_engine.custom_search(url       = 'https://link.springer.com', \n",
    "                                           keyword   = 'Zero-shot learning', \n",
    "                                           max_pages = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56890f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SimZSL: Zero-Shot Learning Beyond a Pre-define...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s112...</td>\n",
       "      <td>Zero-shot learning aims to generalize from a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A review on NLP zero-shot and few-shot learnin...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s424...</td>\n",
       "      <td>Zero-shot and few-shot learning are critical a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zero-Shot Learning | SpringerLink</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/978-...</td>\n",
       "      <td>Zero-shot learning (ZSL) manages to build mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Research progress of zero-shot learning | Appl...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s104...</td>\n",
       "      <td>ZSL can be regarded as a special type of cross...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A study on zero-shot learning from semantic vi...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s003...</td>\n",
       "      <td>A zero-shot learning model trained on labeled ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zero-Shot Learning in Cybersecurity: A Paradig...</td>\n",
       "      <td>https://link.springer.com/chapter/10.1007/978-...</td>\n",
       "      <td>This paper explores the application of zero-sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Semantics-Conditioned Generative Zero-Shot Lea...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s112...</td>\n",
       "      <td>Generative zero-shot learning (ZSL) recognizes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Positional embeddings and zero-shot learning u...</td>\n",
       "      <td>https://link.springer.com/article/10.1186/s133...</td>\n",
       "      <td>This method provides a fixed encoding that is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Semantics-Guided Intra-Category Knowledge Tran...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s112...</td>\n",
       "      <td>Zero-shot learning (ZSL) requires one to assoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zero-shot learning via categorization-relevant...</td>\n",
       "      <td>https://link.springer.com/article/10.1007/s003...</td>\n",
       "      <td>Zero-shot learning (ZSL) trains classifiers on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  SimZSL: Zero-Shot Learning Beyond a Pre-define...   \n",
       "1  A review on NLP zero-shot and few-shot learnin...   \n",
       "2                  Zero-Shot Learning | SpringerLink   \n",
       "3  Research progress of zero-shot learning | Appl...   \n",
       "4  A study on zero-shot learning from semantic vi...   \n",
       "5  Zero-Shot Learning in Cybersecurity: A Paradig...   \n",
       "6  Semantics-Conditioned Generative Zero-Shot Lea...   \n",
       "7  Positional embeddings and zero-shot learning u...   \n",
       "8  Semantics-Guided Intra-Category Knowledge Tran...   \n",
       "9  Zero-shot learning via categorization-relevant...   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://link.springer.com/article/10.1007/s112...   \n",
       "1  https://link.springer.com/article/10.1007/s424...   \n",
       "2  https://link.springer.com/chapter/10.1007/978-...   \n",
       "3  https://link.springer.com/article/10.1007/s104...   \n",
       "4  https://link.springer.com/article/10.1007/s003...   \n",
       "5  https://link.springer.com/chapter/10.1007/978-...   \n",
       "6  https://link.springer.com/article/10.1007/s112...   \n",
       "7  https://link.springer.com/article/10.1186/s133...   \n",
       "8  https://link.springer.com/article/10.1007/s112...   \n",
       "9  https://link.springer.com/article/10.1007/s003...   \n",
       "\n",
       "                                             snippet  \n",
       "0  Zero-shot learning aims to generalize from a s...  \n",
       "1  Zero-shot and few-shot learning are critical a...  \n",
       "2  Zero-shot learning (ZSL) manages to build mode...  \n",
       "3  ZSL can be regarded as a special type of cross...  \n",
       "4  A zero-shot learning model trained on labeled ...  \n",
       "5  This paper explores the application of zero-sh...  \n",
       "6  Generative zero-shot learning (ZSL) recognizes...  \n",
       "7  This method provides a fixed encoding that is ...  \n",
       "8  Zero-shot learning (ZSL) requires one to assoc...  \n",
       "9  Zero-shot learning (ZSL) trains classifiers on...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "websit_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28a5d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "                         RESP API Usage Examples\n",
      "================================================================================\n",
      "\n",
      "\n",
      "### EXAMPLE 1: Arxiv Search (Simple API) ###\n",
      "--------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:11<00:00,  5.69s/it]\n",
      "Found 100 papers from Arxiv\n",
      "\n",
      "First paper:\n",
      "  Title: TIE: A Training-Inversion-Exclusion Framework for Visually Interpretable and Uncertainty-Guided Out-of-Distribution Detection\n",
      "  Link:  https://arxiv.org/abs/2512.00229\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\n",
      "Custom search found 50 papers\n",
      "\n",
      "\n",
      "### EXAMPLE 2: Semantic Scholar Search (Simple API) ###\n",
      "--------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.91s/it]\n",
      "Found 10 papers from Semantic Scholar\n",
      "\n",
      "First paper:\n",
      "  Title: Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing\n",
      "  Link:  http://dl.acm.org/citation.cfm?id=3560815\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.88s/it]\n",
      "\n",
      "Filtered search (2018-2024) found 10 papers\n",
      "\n",
      "\n",
      "### EXAMPLE 3: ACM Digital Library Search (Simple API) ###\n",
      "--------------------------------------------------------------------------------\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Warning: Could not find expected ACM page structure. Website may have changed.\n",
      "Trying alternative selectors...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.10s/it]\n",
      "‚ö† ACM returned no results (website structure may have changed)\n",
      "\n",
      "\n",
      "### EXAMPLE 4: Google Scholar Search (Simple API) ###\n",
      "--------------------------------------------------------------------------------\n",
      "‚Ñπ Google Scholar requires a SerpAPI key\n",
      "  Set it via: google_scholar.set_api_key('your_key')\n",
      "  Or environment variable: export SERPAPI_KEY='your_key'\n",
      "  Get a free key at: https://serpapi.com/\n",
      "\n",
      "\n",
      "### EXAMPLE 5: Arxiv (Advanced API - Direct Class Import) ###\n",
      "--------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.71s/it]\n",
      "Found 50 papers using Arxiv class\n",
      "Columns: ['title', 'link']\n",
      "\n",
      "\n",
      "### EXAMPLE 6: Semantic Scholar (Advanced API - Direct Class Import) ###\n",
      "--------------------------------------------------------------------------------\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.77s/it]\n",
      "Found 10 papers using Semantic_Scholar class\n",
      "Columns: ['title', 'link']\n",
      "\n",
      "\n",
      "### EXAMPLE 7: ACM Digital Library (Advanced API - Direct Class Import) ###\n",
      "--------------------------------------------------------------------------------\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Warning: Could not find expected ACM page structure. Website may have changed.\n",
      "Trying alternative selectors...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:03<00:00,  3.07s/it]\n",
      "Found 0 papers using ACM class\n",
      "\n",
      "\n",
      "### EXAMPLE 8: Google Scholar via Serp (Advanced API) ###\n",
      "--------------------------------------------------------------------------------\n",
      "‚Ñπ Skipping - requires SERPAPI_KEY environment variable\n",
      "\n",
      "\n",
      "### EXAMPLE 9: Resp Class for Multiple Academic Sources ###\n",
      "--------------------------------------------------------------------------------\n",
      "‚Ñπ Resp class requires SerpAPI key (uses Google search)\n",
      "  The Resp class provides access to multiple academic sources:\n",
      "  - ACL Anthology, PMLR, NeurIPS, IJCAI, OpenReview, CVF\n",
      "  Set SERPAPI_KEY environment variable to use this feature\n",
      "\n",
      "\n",
      "### EXAMPLE 10: Comparing Results from Multiple Sources ###\n",
      "--------------------------------------------------------------------------------\n",
      "Searching for 'transformer architecture' across multiple sources...\n",
      "\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:06<00:00,  6.23s/it]\n",
      "Arxiv:            50 papers\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:07<00:00,  7.29s/it]\n",
      "Semantic Scholar: 10 papers\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]Warning: Could not find expected ACM page structure. Website may have changed.\n",
      "Trying alternative selectors...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:05<00:00,  5.08s/it]\n",
      "ACM:              0 papers\n",
      "\n",
      "Total papers found: 60\n",
      "\n",
      "\n",
      "================================================================================\n",
      "                              EXAMPLES COMPLETE\n",
      "================================================================================\n",
      "\n",
      "‚úÖ All examples executed successfully!\n",
      "\n",
      "Key Takeaways:\n",
      "  ‚Ä¢ Simple API: Use 'from resp import arxiv, semantic_scholar, ...'\n",
      "  ‚Ä¢ Advanced API: Import classes directly for more control\n",
      "  ‚Ä¢ Most sources are FREE (no API key needed)\n",
      "  ‚Ä¢ Google Scholar requires SerpAPI key from https://serpapi.com/\n",
      "\n",
      "For more information, visit: https://github.com/monk1337/resp\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "!python3 api_uses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e76617-305c-4c3a-a6f1-c10214ffc25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
